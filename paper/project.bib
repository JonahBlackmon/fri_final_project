@inproceedings{10.1145/1228716.1228751,
author = {Calinon, Sylvain and Billard, Aude},
title = {Incremental learning of gestures by imitation in a humanoid robot},
year = {2007},
isbn = {9781595936172},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1228716.1228751},
doi = {10.1145/1228716.1228751},
abstract = {We present an approach to teach incrementally human gestures to a humanoid robot. By using active teaching methods that puts the human teacher "in the loop" of the robot's learning, we show that the essential characteristics of a gesture can be efficiently transferred by interacting socially with the robot. In a first phase, the robot observes the user demonstrating the skill while wearing motion sensors. The motion of his/her two arms and head are recorded by the robot, projected in a latent space of motion and encoded bprobabilistically in a Gaussian Mixture Model (GMM). In a second phase, the user helps the robot refine its gesture by kinesthetic teaching, i.e. by grabbing and moving its arms throughout the movement to provide the appropriate scaffolds. To update the model of the gesture, we compare the performance of two incremental training procedures against a batch training procedure. We present experiments to show that different modalities can be combined efficiently to teach incrementally basketball officials' signals to a HOAP-3 humanoid robot.},
booktitle = {Proceedings of the ACM/IEEE International Conference on Human-Robot Interaction},
pages = {255–262},
numpages = {8},
keywords = {programming by demonstration, incremental learning, imitation learning, gaussian mixture model},
location = {Arlington, Virginia, USA},
series = {HRI '07}
}

@Article{app8020241,
AUTHOR = {Burns, Rachael and Jeon, Myounghoon and Park, Chung Hyuk},
TITLE = {Robotic Motion Learning Framework to Promote Social Engagement},
JOURNAL = {Applied Sciences},
VOLUME = {8},
YEAR = {2018},
NUMBER = {2},
ARTICLE-NUMBER = {241},
URL = {https://www.mdpi.com/2076-3417/8/2/241},
ISSN = {2076-3417},
ABSTRACT = {Imitation is a powerful component of communication between people, and it poses an important implication in improving the quality of interaction in the field of human–robot interaction (HRI). This paper discusses a novel framework designed to improve human–robot interaction through robotic imitation of a participant’s gestures. In our experiment, a humanoid robotic agent socializes with and plays games with a participant. For the experimental group, the robot additionally imitates one of the participant’s novel gestures during a play session. We hypothesize that the robot’s use of imitation will increase the participant’s openness towards engaging with the robot. Experimental results from a user study of 12 subjects show that post-imitation, experimental subjects displayed a more positive emotional state, had higher instances of mood contagion towards the robot, and interpreted the robot to have a higher level of autonomy than their control group counterparts did. These results point to an increased participant interest in engagement fueled by personalized imitation during interaction.},
DOI = {10.3390/app8020241}
}

@article{article,
author = {Tiferes, Judith and Hussein, Ahmed and Bisantz, Ann and Higginbotham, Jeffery and Sharif, Mohamed and Kozlowski, Justen and Ahmad, Basel and O'Hara, Ryan and Wawrzyniak, Nicole and Guru, Khurshid},
year = {2018},
month = {03},
pages = {},
title = {Are gestures worth a thousand words? Verbal and nonverbal communication during robot-assisted surgery},
volume = {78},
journal = {Applied Ergonomics},
doi = {10.1016/j.apergo.2018.02.015}
}
